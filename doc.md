√ìtimo! Vamos come√ßar analisando os potenciais problemas no fluxo b√°sico, onde o Servi√ßo A envia uma mensagem para o Servi√ßo B:

### Problemas Comuns
1. **Falha no envio da mensagem**: O Servi√ßo A pode enfrentar problemas ao publicar mensagens no Kafka (por exemplo, falhas de conectividade, configura√ß√£o incorreta do cluster, ou indisponibilidade do broker).
2. **Duplica√ß√£o de mensagens**: O Servi√ßo A pode enviar a mesma mensagem mais de uma vez devido a falhas de rede ou comportamento "at least once".
3. **Indisponibilidade do consumidor**: O Servi√ßo B pode estar indispon√≠vel no momento em que a mensagem √© publicada.
4. **Erros de processamento**: O Servi√ßo B pode encontrar erros ao tentar processar a mensagem, seja por problemas de l√≥gica ou por dados inv√°lidos.
5. **Perda de mensagens**: Mensagens podem ser perdidas se o consumidor n√£o as processar antes de uma falha.
6. **Problemas de deserializa√ß√£o**: O formato da mensagem pode n√£o ser compat√≠vel entre o produtor e o consumidor.

### Estrat√©gias para Resili√™ncia
#### 1. **Retries**
- **Produtor**: Configure `retries` no Kafka Producer para reenviar mensagens automaticamente em caso de falhas tempor√°rias.
- **Consumidor**: Utilize uma l√≥gica de retry personalizada para reprocessar mensagens que falharem no consumidor.
  
#### 2. **DLQ (Dead Letter Queue)**
- Configure uma fila dedicada para armazenar mensagens que falharem ap√≥s um n√∫mero configur√°vel de tentativas de processamento. Isso evita a perda de dados e permite an√°lises posteriores.

#### 3. **Idempot√™ncia**
- Configure o Kafka Producer para garantir idempot√™ncia (`enable.idempotence=true`). Assim, m√∫ltiplos envios da mesma mensagem n√£o resultam em duplica√ß√µes.

#### 4. **Timeouts e Circuit Breaker**
- No Servi√ßo A, implemente um timeout para evitar bloqueios em caso de indisponibilidade do Kafka.
- No Servi√ßo B, utilize um circuito breaker para pausar o consumo quando ocorrerem falhas repetidas.

#### 5. **Persist√™ncia Local**
- No Servi√ßo A, armazene mensagens em um armazenamento local (como um banco de dados) antes de envi√°-las para o Kafka, para garantir persist√™ncia em caso de falha.

#### 6. **Deserializa√ß√£o Robusta**
- Valide o esquema das mensagens usando ferramentas como Avro ou JSON Schema antes do envio e durante o consumo.

### Pr√≥ximos Passos
1. Criar uma implementa√ß√£o inicial do fluxo b√°sico com Spring Boot:
   - Servi√ßo A (producer) publica mensagens no Kafka.
   - Servi√ßo B (consumer) consome e processa as mensagens.

2. Adicionar resili√™ncia incrementalmente:
   - Configurar retries no produtor e no consumidor.
   - Implementar DLQ para mensagens n√£o process√°veis.
   - Garantir idempot√™ncia no produtor.

Voc√™ quer come√ßar com a configura√ß√£o inicial do fluxo b√°sico ou j√° introduzir alguma t√©cnica de resili√™ncia?




Perfeito! Vamos come√ßar com o fluxo mais b√°sico, onde o Servi√ßo A envia uma mensagem para o Kafka, e o Servi√ßo B consome e processa essa mensagem. Isso ser√° o "Hello World" da nossa arquitetura.

### Passo 1: Configura√ß√£o Inicial

#### 1. **Pr√©-requisitos**
Certifique-se de ter o seguinte:
- **Kafka**: Um cluster Kafka em execu√ß√£o (pode ser local usando `docker-compose`).
- **Spring Boot**: Dois projetos Spring Boot configurados com depend√™ncias do Kafka.

Adicione as depend√™ncias necess√°rias no `pom.xml` de ambos os servi√ßos:

```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>
</dependencies>
```

#### 2. **Configura√ß√£o do Kafka no `application.yml`**

##### Servi√ßo A (Producer)
```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
```

##### Servi√ßo B (Consumer)
```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: service-b-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: earliest
```

#### 3. **Produ√ß√£o e Consumo de Mensagens**

##### Servi√ßo A: Producer
```java
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class ProducerController {
    private final KafkaTemplate<String, String> kafkaTemplate;

    public ProducerController(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    @GetMapping("/send")
    public String sendMessage() {
        kafkaTemplate.send("example-topic", "Hello, Kafka!");
        return "Message sent!";
    }
}
```

##### Servi√ßo B: Consumer
```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;

@Service
public class MessageConsumer {
    @KafkaListener(topics = "example-topic", groupId = "service-b-group")
    public void consume(String message) {
        System.out.println("Received message: " + message);
    }
}
```

### Passo 2: Testar o Fluxo
1. Inicie o Kafka localmente.
2. Suba o Servi√ßo B para que ele esteja ouvindo no t√≥pico `example-topic`.
3. Suba o Servi√ßo A e acesse a URL `http://localhost:8080/send` para disparar a mensagem.
4. Verifique os logs do Servi√ßo B para garantir que a mensagem foi recebida.

Esse √© o fluxo b√°sico funcionando. Queremos partir daqui para algum ponto espec√≠fico na evolu√ß√£o?




√ìtimo! Com o fluxo b√°sico funcionando, podemos come√ßar a adicionar resili√™ncia de forma incremental. Aqui est√£o algumas dire√ß√µes poss√≠veis para o pr√≥ximo passo:

1. **Retries no Consumidor**: Implementar tentativas de reprocessamento para lidar com falhas tempor√°rias ao processar uma mensagem.
2. **DLQ (Dead Letter Queue)**: Adicionar uma fila para mensagens que falharem ap√≥s m√∫ltiplas tentativas.
3. **Garantir Idempot√™ncia no Producer**: Configurar idempot√™ncia para evitar duplica√ß√£o de mensagens.
4. **Persist√™ncia Local no Producer**: Garantir que mensagens sejam armazenadas localmente antes de serem enviadas ao Kafka.

Qual dessas melhorias voc√™ prefere implementar agora?


Perfeito! Vamos tratar o cen√°rio de **falhas no envio da mensagem pelo producer**, garantindo que ele lide com problemas como indisponibilidade do broker ou falhas tempor√°rias de rede.

### Passo 1: Configura√ß√£o de Retries no Producer
O Kafka Producer oferece uma funcionalidade nativa para reenvio autom√°tico de mensagens em caso de falha.

#### Ajuste no `application.yml` do Servi√ßo A
```yaml
spring:
  kafka:
    producer:
      retries: 5  # N√∫mero de tentativas de reenvio
      acks: all  # Garante que a mensagem ser√° confirmada por todos os brokers replicados
      linger-ms: 5  # Opcional: Reduz a lat√™ncia ao agrupar mensagens
      batch-size: 16384  # Opcional: Configura√ß√£o de tamanho de batch para otimiza√ß√£o
```

#### Explica√ß√£o
- `retries`: O n√∫mero de vezes que o producer tentar√° reenviar uma mensagem antes de falhar.
- `acks`: Define o n√≠vel de confirma√ß√£o requerido. O valor `all` garante que todos os brokers replicados confirmem o recebimento antes de prosseguir.
- `linger-ms` e `batch-size`: Melhoram a performance enviando mensagens em lotes, mas s√£o opcionais.

---

### Passo 2: Tratamento de Exce√ß√µes no Producer
Mesmo com retries configurados, √© essencial lidar com exce√ß√µes no caso de falhas persistentes.

#### Ajuste no Producer com um Callback
```java
import org.apache.kafka.clients.producer.RecordMetadata;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

@Service
public class ReliableProducer {
    private final KafkaTemplate<String, String> kafkaTemplate;

    public ReliableProducer(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public void sendMessage(String topic, String message) {
        kafkaTemplate.send(topic, message).addCallback(
            result -> {
                if (result != null) {
                    RecordMetadata metadata = result.getRecordMetadata();
                    System.out.println("Message sent successfully to " +
                            metadata.topic() + " partition " + metadata.partition() +
                            " at offset " + metadata.offset());
                }
            },
            ex -> {
                System.err.println("Failed to send message: " + ex.getMessage());
                // Opcional: persistir a mensagem localmente para retry posterior
            }
        );
    }
}
```

---

### Passo 3: Persist√™ncia Local para Garantia
Se o producer falhar ap√≥s todas as tentativas, voc√™ pode armazenar a mensagem localmente para reenvio manual ou autom√°tico mais tarde.

#### Exemplo usando um Banco de Dados Local
```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.stereotype.Repository;

@Repository
public class FailedMessagesRepository {

    @Autowired
    private JdbcTemplate jdbcTemplate;

    public void saveFailedMessage(String topic, String message) {
        jdbcTemplate.update("INSERT INTO failed_messages (topic, message) VALUES (?, ?)", topic, message);
    }
}
```

#### Integra√ß√£o com o Producer
```java
public void sendMessage(String topic, String message) {
    kafkaTemplate.send(topic, message).addCallback(
        result -> System.out.println("Message sent successfully!"),
        ex -> {
            System.err.println("Failed to send message: " + ex.getMessage());
            failedMessagesRepository.saveFailedMessage(topic, message);
        }
    );
}
```

---

### Teste do Cen√°rio de Falha
1. Simule uma falha no Kafka (desligue o broker).
2. Tente enviar uma mensagem pelo Servi√ßo A.
3. Observe que:
   - O producer tenta reenviar a mensagem (retries).
   - Ap√≥s esgotar as tentativas, a mensagem √© registrada no banco de dados.

### Pr√≥ximos Passos
Se esta parte fizer sentido, podemos:
1. Adicionar uma rotina para reprocessar mensagens falhadas do banco.
2. Evoluir para a implementa√ß√£o de DLQ e resili√™ncia no consumidor.

Para reprocessar mensagens falhadas do banco, podemos criar uma rotina que seja executada periodicamente ou manualmente, reenvie as mensagens armazenadas, e marque-as como processadas ao serem enviadas com sucesso. 

### Passo 1: Estrutura do Banco de Dados
Certifique-se de ter uma tabela para armazenar mensagens falhadas com uma estrutura b√°sica:

```sql
CREATE TABLE failed_messages (
    id SERIAL PRIMARY KEY,
    topic VARCHAR(255) NOT NULL,
    message TEXT NOT NULL,
    retry_count INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

- `retry_count`: Para registrar o n√∫mero de tentativas realizadas.
- `created_at`: Para implementar pol√≠ticas de expira√ß√£o, se necess√°rio.

---

### Passo 2: Criar o Servi√ßo de Reprocessamento
Crie um servi√ßo que fa√ßa a leitura das mensagens falhadas e tente reenvi√°-las ao Kafka.

#### Servi√ßo de Reprocessamento
```java
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.List;

@Service
public class FailedMessageProcessor {

    private final FailedMessagesRepository repository;
    private final KafkaTemplate<String, String> kafkaTemplate;

    public FailedMessageProcessor(FailedMessagesRepository repository, KafkaTemplate<String, String> kafkaTemplate) {
        this.repository = repository;
        this.kafkaTemplate = kafkaTemplate;
    }

    @Scheduled(fixedDelay = 10000) // Reprocessa a cada 10 segundos
    @Transactional
    public void reprocessMessages() {
        List<FailedMessage> failedMessages = repository.findTop10(); // Reprocessar em lotes
        for (FailedMessage message : failedMessages) {
            try {
                kafkaTemplate.send(message.getTopic(), message.getMessage()).get(); // Sincrono para garantir envio
                repository.deleteById(message.getId()); // Remove do banco ap√≥s sucesso
                System.out.println("Message reprocessed successfully: " + message.getMessage());
            } catch (Exception ex) {
                System.err.println("Failed to reprocess message: " + message.getMessage());
                repository.incrementRetryCount(message.getId()); // Incrementa o contador de retries
            }
        }
    }
}
```

---

### Passo 3: Repository para Mensagens Falhadas
Implemente o reposit√≥rio com m√©todos para buscar mensagens em lotes e atualizar o contador de retries.

#### Repository
```java
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.stereotype.Repository;

import java.util.List;

@Repository
public class FailedMessagesRepository {

    private final JdbcTemplate jdbcTemplate;

    public FailedMessagesRepository(JdbcTemplate jdbcTemplate) {
        this.jdbcTemplate = jdbcTemplate;
    }

    public List<FailedMessage> findTop10() {
        return jdbcTemplate.query(
            "SELECT id, topic, message, retry_count FROM failed_messages ORDER BY created_at ASC LIMIT 10",
            (rs, rowNum) -> new FailedMessage(
                rs.getLong("id"),
                rs.getString("topic"),
                rs.getString("message"),
                rs.getInt("retry_count")
            )
        );
    }

    public void deleteById(Long id) {
        jdbcTemplate.update("DELETE FROM failed_messages WHERE id = ?", id);
    }

    public void incrementRetryCount(Long id) {
        jdbcTemplate.update("UPDATE failed_messages SET retry_count = retry_count + 1 WHERE id = ?", id);
    }
}
```

---

### Passo 4: Configura√ß√£o para Execu√ß√£o Agendada
Adicione a anota√ß√£o `@EnableScheduling` na classe principal do Spring Boot para habilitar a execu√ß√£o do m√©todo agendado.

#### Exemplo
```java
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.scheduling.annotation.EnableScheduling;

@SpringBootApplication
@EnableScheduling
public class ProducerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ProducerApplication.class, args);
    }
}
```

---

### Passo 5: Gerenciamento de Retries
1. **Pol√≠tica de Retries**:
   - Limite o n√∫mero de tentativas, por exemplo, para 3.
   - Ap√≥s exceder, mova a mensagem para uma tabela de DLQ ou envie para outro t√≥pico.

2. **Pol√≠tica de Expira√ß√£o**:
   - Exclua mensagens muito antigas (`created_at`) para evitar crescimento descontrolado.

---

### Teste da Rotina
1. Insira manualmente mensagens na tabela `failed_messages` ou cause falhas no envio para popular a tabela.
2. Observe os logs para confirmar o reprocessamento.
3. Verifique se mensagens processadas com sucesso s√£o removidas da tabela.

Esse processo cria uma base robusta para gerenciar mensagens falhadas. Quer evoluir para pol√≠ticas de retries mais avan√ßadas ou come√ßar a lidar com falhas no consumidor?



Se o banco de dados estiver indispon√≠vel, o producer precisar√° de alternativas para garantir que as mensagens falhadas n√£o sejam perdidas e possam ser reprocessadas posteriormente. Aqui est√£o algumas estrat√©gias poss√≠veis:

---

### **1. Persist√™ncia Local no Filesystem**
O producer pode gravar as mensagens falhadas em um arquivo local no sistema de arquivos, que ser√° utilizado para reprocessamento mais tarde.

#### Exemplo: Persistindo Mensagens em Arquivos Locais
```java
import java.io.BufferedWriter;
import java.io.FileWriter;
import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Paths;

public class LocalFileStorage {

    private static final String FILE_PATH = "failed-messages.txt";

    public void saveFailedMessage(String topic, String message) {
        try (BufferedWriter writer = new BufferedWriter(new FileWriter(FILE_PATH, true))) {
            writer.write(topic + "::" + message);
            writer.newLine();
        } catch (IOException e) {
            System.err.println("Failed to write message to file: " + e.getMessage());
        }
    }

    public List<String> readFailedMessages() {
        try {
            return Files.readAllLines(Paths.get(FILE_PATH));
        } catch (IOException e) {
            System.err.println("Failed to read messages from file: " + e.getMessage());
            return Collections.emptyList();
        }
    }

    public void clearFile() {
        try {
            Files.deleteIfExists(Paths.get(FILE_PATH));
        } catch (IOException e) {
            System.err.println("Failed to clear file: " + e.getMessage());
        }
    }
}
```

---

#### Integra√ß√£o com o Producer
Adicione a l√≥gica de fallback no caso de indisponibilidade do banco:

```java
public void sendMessage(String topic, String message) {
    kafkaTemplate.send(topic, message).addCallback(
        result -> System.out.println("Message sent successfully!"),
        ex -> {
            System.err.println("Failed to send message: " + ex.getMessage());
            try {
                failedMessagesRepository.saveFailedMessage(topic, message);
            } catch (Exception dbEx) {
                System.err.println("Failed to save to database, persisting locally...");
                localFileStorage.saveFailedMessage(topic, message);
            }
        }
    );
}
```

---

### **2. Usar Cache Local (In-Memory)**
Se o banco estiver indispon√≠vel, o producer pode armazenar mensagens falhadas temporariamente na mem√≥ria e tentar reprocess√°-las periodicamente.

#### Exemplo com `ConcurrentLinkedQueue`
```java
import java.util.Queue;
import java.util.concurrent.ConcurrentLinkedQueue;

public class InMemoryFailedMessageCache {

    private final Queue<String> failedMessages = new ConcurrentLinkedQueue<>();

    public void saveFailedMessage(String message) {
        failedMessages.add(message);
    }

    public String getFailedMessage() {
        return failedMessages.poll(); // Remove e retorna a pr√≥xima mensagem
    }

    public boolean isEmpty() {
        return failedMessages.isEmpty();
    }
}
```

#### Integra√ß√£o com o Producer
```java
public void sendMessage(String topic, String message) {
    kafkaTemplate.send(topic, message).addCallback(
        result -> System.out.println("Message sent successfully!"),
        ex -> {
            System.err.println("Failed to send message: " + ex.getMessage());
            try {
                failedMessagesRepository.saveFailedMessage(topic, message);
            } catch (Exception dbEx) {
                System.err.println("Failed to save to database, caching in memory...");
                inMemoryFailedMessageCache.saveFailedMessage(topic + "::" + message);
            }
        }
    );
}
```

---

### **3. Fallback para Outra Persist√™ncia**
Se o banco principal estiver indispon√≠vel, configure um banco de dados secund√°rio ou outro armazenamento persistente.

- **Redis** ou **Memcached**: Cache distribu√≠do como fallback para armazenar mensagens temporariamente.
- **NoSQL**: Usar algo como MongoDB ou Cassandra para fallback.

---

### **4. Kafka como Backup (Write to DLQ Topic)**
Se nenhuma op√ß√£o local for vi√°vel, o producer pode enviar as mensagens para um t√≥pico especial no Kafka que serve como "DLQ do Producer".

#### Envio para um T√≥pico de DLQ
```java
public void sendMessage(String topic, String message) {
    kafkaTemplate.send(topic, message).addCallback(
        result -> System.out.println("Message sent successfully!"),
        ex -> {
            System.err.println("Failed to send message: " + ex.getMessage());
            kafkaTemplate.send("producer-dlq", message);
        }
    );
}
```

- **Benef√≠cio**: As mensagens ficam armazenadas no Kafka, e o reprocessamento pode ser feito diretamente de l√°, eliminando a necessidade de persist√™ncia local.
- **Cuidado**: Garante resili√™ncia, mas aumenta a depend√™ncia do Kafka.

---

### **5. Circuit Breaker**
Implemente um **circuit breaker** (usando frameworks como Resilience4j) para pausar a intera√ß√£o com o banco de dados se ele estiver indispon√≠vel, enquanto utiliza uma das estrat√©gias acima.

#### Exemplo com Resilience4j
```java
import io.github.resilience4j.circuitbreaker.CircuitBreaker;
import io.github.resilience4j.circuitbreaker.CircuitBreakerConfig;

import java.time.Duration;

public class CircuitBreakerConfig {

    private final CircuitBreaker circuitBreaker;

    public CircuitBreakerConfig() {
        this.circuitBreaker = CircuitBreaker.of("database", CircuitBreakerConfig.custom()
            .failureRateThreshold(50) // Limite de falhas (em %)
            .waitDurationInOpenState(Duration.ofSeconds(30)) // Tempo de espera para tentar novamente
            .build());
    }

    public CircuitBreaker getCircuitBreaker() {
        return circuitBreaker;
    }
}
```

---

### **Decis√£o Estrat√©gica**
- **Persist√™ncia Local**: Simples e eficaz para sistemas isolados.
- **In-Memory Cache**: √ìtimo para sistemas que t√™m pouca lat√™ncia e consumo r√°pido.
- **Fallback para Kafka DLQ**: Ideal para sistemas event-driven que j√° utilizam Kafka extensivamente.
- **Circuit Breaker**: Garante controle e evita sobrecarregar o banco quando ele est√° parcialmente indispon√≠vel.

Qual dessas abordagens voc√™ prefere implementar primeiro?




A anota√ß√£o `@Retryable` no Spring √© uma abordagem espec√≠fica para implementar a l√≥gica de reprocessamento em caso de falhas. Ela √© frequentemente usada no contexto de m√©todos que podem falhar por raz√µes tempor√°rias e que precisam ser executados novamente, como chamadas a APIs externas, opera√ß√µes de banco de dados, entre outras. A principal diferen√ßa entre `@Retryable` e as configura√ß√µes de retry do Kafka est√° na forma como elas s√£o aplicadas e no escopo da opera√ß√£o de retry.

### 1. **Retry Configurations no Kafka** (`ProducerConfig.RETRIES_CONFIG`)
As configura√ß√µes de retry do Kafka, como o `ProducerConfig.RETRIES_CONFIG` e `ProducerConfig.RETRY_BACKOFF_MS_CONFIG`, s√£o espec√≠ficas para o funcionamento do **producer** do Kafka e controlam como as mensagens s√£o reenviadas para o Kafka quando ocorre uma falha na entrega (geralmente falhas de rede ou problemas tempor√°rios com o broker).

- **Escopo**: Configura√ß√£o de retry no Kafka √© **exclusiva para o envio de mensagens**. Ou seja, se o Kafka falhar ao enviar uma mensagem para um t√≥pico, ele tentar√° reenviar de acordo com as configura√ß√µes de retry.
- **Controle**: O controle sobre a quantidade de tentativas e o intervalo entre elas √© feito diretamente na configura√ß√£o do Kafka e n√£o no c√≥digo de aplica√ß√£o.

### 2. **`@Retryable` do Spring**
A anota√ß√£o `@Retryable` √© uma abstra√ß√£o fornecida pelo Spring que pode ser aplicada a **m√©todos de qualquer tipo**. Ela oferece a capacidade de definir um comportamento de retry para o m√©todo em que √© aplicada, permitindo que o Spring reexecute o m√©todo automaticamente em caso de exce√ß√µes espec√≠ficas. Essa abordagem √© mais flex√≠vel e pode ser usada em diferentes contextos (n√£o se limita a intera√ß√µes com o Kafka).

#### Exemplo de Uso do `@Retryable`:
```java
@Retryable(value = {IOException.class}, maxAttempts = 3, backoff = @Backoff(delay = 1000))
public void sendMessage() throws IOException {
    // M√©todo que tenta enviar uma mensagem e pode falhar com IOException
    messageSender.send();
}
```

- **Escopo**: A anota√ß√£o `@Retryable` funciona no n√≠vel de **m√©todos**. Voc√™ a aplica diretamente no m√©todo que deseja que seja reexecutado em caso de falha. Ela pode ser usada em qualquer tipo de opera√ß√£o (n√£o apenas com Kafka, mas tamb√©m para intera√ß√µes com APIs externas, chamadas de rede, ou qualquer c√≥digo suscet√≠vel a falhas tempor√°rias).
- **Controle**: A anota√ß√£o permite especificar **quantas tentativas** ser√£o feitas (`maxAttempts`), o **intervalo de tempo entre tentativas** (`delay`), e outras estrat√©gias de backoff (como backoff exponencial).

### 3. **Principais Diferen√ßas**

- **Escopo e Contexto**:
  - `@Retryable`: Aplica-se a qualquer m√©todo da sua aplica√ß√£o, permitindo retry em opera√ß√µes gen√©ricas.
  - Kafka Retry: Aplica-se apenas ao contexto de envio de mensagens para o Kafka, controlando como o produtor reage a falhas na entrega de mensagens.

- **Configura√ß√£o**:
  - `@Retryable`: Configurada diretamente no c√≥digo, como uma anota√ß√£o sobre o m√©todo.
  - Kafka Retry: Configurada atrav√©s das propriedades do `ProducerConfig` no Kafka.

- **Flexibilidade**:
  - `@Retryable`: Oferece controle sobre os tipos de exce√ß√µes que disparam a l√≥gica de retry e permite definir par√¢metros de retry detalhados como o delay, backoff exponencial, e o n√∫mero m√°ximo de tentativas.
  - Kafka Retry: Focado nas falhas de comunica√ß√£o com o Kafka e no reenvio de mensagens; n√£o √© t√£o flex√≠vel em termos de controle fino de exce√ß√µes ou backoff.

### 4. **Quando Usar Cada Uma**

- **Kafka Retry**: Se voc√™ est√° lidando com o envio de mensagens para o Kafka e quer controlar o retry de falhas tempor√°rias (como falhas de rede ou problemas com o broker), utilize as configura√ß√µes de retry do Kafka. Elas s√£o ideais para garantir a entrega das mensagens e podem ser facilmente configuradas no `ProducerConfig`.

- **`@Retryable`**: Se voc√™ precisa de retry em uma l√≥gica de aplica√ß√£o mais ampla (por exemplo, tentar novamente ao se comunicar com uma API externa ou ao acessar um banco de dados), a anota√ß√£o `@Retryable` oferece uma maneira f√°cil e flex√≠vel de aplicar o comportamento de retry a m√©todos espec√≠ficos, com a possibilidade de personalizar o comportamento para diferentes exce√ß√µes.

### 5. **Exemplo de Uso Combinado**
Voc√™ pode usar tanto o retry do Kafka quanto o `@Retryable` no Spring juntos, se necess√°rio. Por exemplo, voc√™ pode configurar retries no Kafka para garantir a entrega das mensagens, enquanto aplica o `@Retryable` em m√©todos que lidam com chamadas externas, como APIs, dentro da l√≥gica de aplica√ß√£o.

```java
@Retryable(value = {IOException.class}, maxAttempts = 3, backoff = @Backoff(delay = 1000))
public void callExternalApi() throws IOException {
    // Chamada a API externa que pode falhar temporariamente
    externalApiClient.call();
}
``` 

Essa combina√ß√£o d√° flexibilidade para garantir que voc√™ trate falhas de forma robusta tanto nas intera√ß√µes com o Kafka quanto com outros componentes da aplica√ß√£o.

# V1


Vamos implementar retries no consumidor! A ideia √© que, ao processar uma mensagem e encontrar um erro tempor√°rio, o sistema tente processar a mensagem novamente antes de considerar a falha definitiva.

### Passo 1: Configurar Retries no Consumidor

#### 1. Adicione Depend√™ncias para Suporte a Retries
Certifique-se de que o projeto j√° tem as depend√™ncias do Spring Kafka. Caso contr√°rio, atualize o `pom.xml`:

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```

#### 2. Ajuste as Configura√ß√µes do Kafka no `application.yml`

```yaml
spring:
  kafka:
    consumer:
      group-id: service-b-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: earliest
    listener:
      ack-mode: record
    template:
      default-topic: example-topic
```

#### 3. Modifique o Consumer para Lidar com Falhas

Adicione um manipulador de erros e configure um `RetryTemplate` para gerenciar as tentativas.

##### Configura√ß√£o do RetryTemplate

Crie uma classe de configura√ß√£o para o Kafka:

```java
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.listener.DefaultErrorHandler;
import org.springframework.retry.policy.SimpleRetryPolicy;
import org.springframework.retry.support.RetryTemplate;

@Configuration
public class KafkaRetryConfig {

    @Bean
    public DefaultErrorHandler errorHandler() {
        RetryTemplate retryTemplate = RetryTemplate.builder()
                .maxAttempts(3)  // Tentar processar a mensagem at√© 3 vezes
                .fixedBackoff(1000)  // Intervalo de 1 segundo entre as tentativas
                .build();

        return new DefaultErrorHandler((rec, ex) -> {
            System.err.println("Mensagem movida para DLQ ap√≥s falhas: " + rec.value());
        }, retryTemplate);
    }
}
```

##### Atualize o Consumer para Usar o ErrorHandler

No consumidor, use o `DefaultErrorHandler` para gerenciar falhas:

```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.listener.DefaultErrorHandler;
import org.springframework.stereotype.Service;

@Service
public class MessageConsumer {

    private final DefaultErrorHandler errorHandler;

    public MessageConsumer(DefaultErrorHandler errorHandler) {
        this.errorHandler = errorHandler;
    }

    @KafkaListener(topics = "example-topic", groupId = "service-b-group")
    public void consume(String message) {
        try {
            System.out.println("Processing message: " + message);
            // Simule um erro para testar o retry
            if (message.contains("fail")) {
                throw new RuntimeException("Erro ao processar mensagem");
            }
        } catch (Exception e) {
            errorHandler.handle(null, e, null);
            throw e;  // Rethrow para acionar o retry
        }
    }
}
```

### Passo 2: Testar Retries
1. Envie uma mensagem com o texto `"Hello, Kafka!"` para validar o consumo bem-sucedido.
2. Envie uma mensagem com o texto `"fail"` para simular falhas e verificar as tentativas de reprocessamento.
3. Confirme que o sistema tenta reprocessar a mensagem 3 vezes antes de falhar definitivamente.

Queremos incluir um DLQ para armazenar mensagens n√£o processadas ap√≥s as tentativas ou ajustar algum aspecto dessa implementa√ß√£o?



Adicionar uma **Dead Letter Queue (DLQ)** √© uma √≥tima maneira de lidar com mensagens que n√£o podem ser processadas ap√≥s v√°rias tentativas. A DLQ armazenar√° essas mensagens para an√°lise posterior, garantindo que nenhuma mensagem seja perdida.

### Passo 1: Configurar a DLQ no Kafka
1. Crie um t√≥pico dedicado para a DLQ:
   - Nome sugerido: `example-topic-dlq`.
   - Use ferramentas como `kafka-topics.sh` ou um painel de administra√ß√£o do Kafka para criar o t√≥pico.

### Passo 2: Ajustar o Consumer para Usar a DLQ

#### 1. Atualizar Configura√ß√£o no `application.yml`
Adicione a configura√ß√£o da DLQ no consumidor:

```yaml
spring:
  kafka:
    consumer:
      group-id: service-b-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: earliest
    listener:
      ack-mode: record
    template:
      default-topic: example-topic
    dead-letter-topic: example-topic-dlq
```

#### 2. Atualizar o `DefaultErrorHandler`
Modifique a configura√ß√£o para enviar mensagens para o t√≥pico DLQ ap√≥s falhas definitivas.

```java
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.header.internals.RecordHeader;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.listener.DefaultErrorHandler;
import org.springframework.retry.support.RetryTemplate;

@Configuration
public class KafkaRetryConfig {

    private final KafkaTemplate<String, String> kafkaTemplate;

    public KafkaRetryConfig(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    @Bean
    public DefaultErrorHandler errorHandler() {
        RetryTemplate retryTemplate = RetryTemplate.builder()
                .maxAttempts(3)
                .fixedBackoff(1000)
                .build();

        return new DefaultErrorHandler((ConsumerRecord<?, ?> record, Exception ex) -> {
            System.err.println("Falha definitiva. Movendo mensagem para DLQ: " + record.value());
            kafkaTemplate.send(new ProducerRecord<>(
                    "example-topic-dlq",
                    null,
                    record.key() == null ? null : record.key().toString(),
                    record.value().toString(),
                    record.headers()
            ));
        }, retryTemplate);
    }
}
```

#### 3. Consumir Mensagens da DLQ (Opcional)
Se voc√™ quiser processar ou analisar as mensagens da DLQ, configure outro consumidor:

```java
@Service
public class DlqConsumer {

    @KafkaListener(topics = "example-topic-dlq", groupId = "dlq-group")
    public void consumeDlq(String message) {
        System.out.println("Mensagem da DLQ: " + message);
        // Aqui voc√™ pode salvar em um banco de dados ou enviar alertas.
    }
}
```

### Passo 3: Testar a DLQ
1. **Cen√°rio Feliz**: Envie uma mensagem como `"Hello, Kafka!"` e confirme o processamento bem-sucedido.
2. **Cen√°rio de Falha**: Envie uma mensagem como `"fail"`. A mensagem deve falhar 3 vezes (retry) e, em seguida, ser movida para o t√≥pico `example-topic-dlq`.
3. **Verificar DLQ**: Verifique se a mensagem aparece no consumidor da DLQ ou use ferramentas de administra√ß√£o do Kafka para visualiz√°-la.

### Pr√≥ximo Passo
Se desejar, podemos:
- Melhorar o fluxo adicionando metadados √† mensagem antes de mov√™-la para a DLQ.
- Implementar alertas autom√°ticos para mensagens na DLQ.
- Passar para outra t√©cnica de resili√™ncia, como **idempot√™ncia** ou **persist√™ncia local no producer**. 

Qual √© o pr√≥ximo passo? üòä




A **persist√™ncia local no Producer** √© uma boa pr√°tica para garantir que as mensagens sejam armazenadas temporariamente antes de serem enviadas ao Kafka, caso ocorra uma falha durante o envio. Isso pode ser especialmente √∫til em situa√ß√µes em que o Kafka est√° temporariamente inacess√≠vel ou quando o producer precisa ser reiniciado. Ao armazenar as mensagens localmente, voc√™ pode garantir que elas n√£o sejam perdidas.

Aqui est√£o os passos para implementar essa persist√™ncia:

---

### Passo 1: Armazenamento Local (Persist√™ncia em Arquivo ou Banco de Dados)

Para persistir localmente, voc√™ pode usar uma abordagem simples, como escrever as mensagens em um arquivo (por exemplo, no formato JSON ou texto). Outra alternativa seria persistir em um banco de dados, mas vamos come√ßar com uma solu√ß√£o mais simples usando arquivos.

#### 1. Cria√ß√£o de um Servi√ßo de Persist√™ncia

Vamos criar um servi√ßo para persistir as mensagens em um arquivo antes de envi√°-las ao Kafka.

```java
import java.io.FileWriter;
import java.io.IOException;
import java.io.PrintWriter;
import org.springframework.stereotype.Service;

@Service
public class LocalPersistenceService {

    private static final String FILE_PATH = "messages-to-send.txt";

    public void persistMessage(String key, String value) {
        try (FileWriter fileWriter = new FileWriter(FILE_PATH, true);
             PrintWriter printWriter = new PrintWriter(fileWriter)) {
            printWriter.printf("Key: %s, Message: %s%n", key, value);
        } catch (IOException e) {
            System.err.println("Erro ao persistir a mensagem: " + e.getMessage());
        }
    }

    public boolean hasMessagesToSend() {
        // M√©todo para verificar se h√° mensagens armazenadas para reenvio
        return new java.io.File(FILE_PATH).exists();
    }
}
```

#### 2. Modificar o Producer para Usar a Persist√™ncia Local

Agora, vamos modificar o `MessageProducer` para usar o `LocalPersistenceService` e garantir que as mensagens sejam armazenadas antes de serem enviadas ao Kafka.

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

@Service
public class MessageProducer {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final LocalPersistenceService persistenceService;

    @Autowired
    public MessageProducer(KafkaTemplate<String, String> kafkaTemplate, LocalPersistenceService persistenceService) {
        this.kafkaTemplate = kafkaTemplate;
        this.persistenceService = persistenceService;
    }

    public void sendMessage(String key, String value) {
        // Persistir a mensagem localmente antes de enviar ao Kafka
        persistenceService.persistMessage(key, value);

        kafkaTemplate.send("example-topic", key, value)
            .addCallback(
                result -> System.out.println("Mensagem enviada com sucesso: " + value),
                ex -> {
                    System.err.println("Erro ao enviar mensagem: " + ex.getMessage());
                    // Caso o envio falhe, a mensagem j√° est√° persistida e pode ser reenviada depois
                }
            );
    }
}
```

### Passo 2: Implementar Reenvio de Mensagens Persistidas

Caso a aplica√ß√£o falhe ou o Kafka esteja temporariamente inacess√≠vel, podemos implementar um mecanismo para reprocessar as mensagens armazenadas localmente. Vamos criar um m√©todo para tentar enviar as mensagens armazenadas.

#### 1. Criar um Servi√ßo de Reenvio

```java
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.List;
import java.util.stream.Collectors;

@Service
public class MessageResendService {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final LocalPersistenceService persistenceService;

    @Autowired
    public MessageResendService(KafkaTemplate<String, String> kafkaTemplate, LocalPersistenceService persistenceService) {
        this.kafkaTemplate = kafkaTemplate;
        this.persistenceService = persistenceService;
    }

    public void resendMessages() {
        // Verifique se h√° mensagens persistidas
        if (persistenceService.hasMessagesToSend()) {
            try {
                List<String> messages = Files.readAllLines(Paths.get("messages-to-send.txt"))
                    .stream()
                    .collect(Collectors.toList());

                for (String message : messages) {
                    // Enviar as mensagens para o Kafka
                    String[] parts = message.split(", ");
                    String key = parts[0].split(": ")[1];
                    String value = parts[1].split(": ")[1];

                    kafkaTemplate.send("example-topic", key, value)
                        .addCallback(
                            result -> System.out.println("Mensagem reenviada com sucesso: " + value),
                            ex -> System.err.println("Erro ao reenviar mensagem: " + ex.getMessage())
                        );
                }
            } catch (Exception e) {
                System.err.println("Erro ao processar mensagens para reenvio: " + e.getMessage());
            }
        }
    }
}
```

#### 2. Programar o Reenvio (Caso a Aplica√ß√£o Reinicie)
Voc√™ pode configurar um agendador (por exemplo, com Spring Scheduler) para tentar reenviar as mensagens persistidas periodicamente, caso o Kafka esteja acess√≠vel.

```java
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

@Component
public class ScheduledMessageResend {

    private final MessageResendService resendService;

    public ScheduledMessageResend(MessageResendService resendService) {
        this.resendService = resendService;
    }

    @Scheduled(fixedRate = 5000)  // Tentar reenviar a cada 5 segundos
    public void resendPersistedMessages() {
        resendService.resendMessages();
    }
}
```

### Passo 3: Testar a Persist√™ncia Local
1. **Enviar Mensagens**: Envie algumas mensagens usando o `MessageProducer`.
2. **Simular Falha de Envio**: Pare o Kafka ou force uma falha de rede para ver se as mensagens s√£o persistidas no arquivo.
3. **Reiniciar a Aplica√ß√£o**: Ap√≥s reiniciar, verifique se as mensagens persistidas s√£o reenviadas para o Kafka.

### Passo 4: Melhorias e Alternativas

- **Persist√™ncia com Banco de Dados**: Em vez de usar arquivos, voc√™ pode utilizar um banco de dados para armazenar mensagens persistidas. Isso pode ser mais eficiente e escal√°vel.
- **Persist√™ncia em uma Fila Local (como um Banco de Mensagens Local)**: Para maior resili√™ncia, pode-se at√© usar uma fila local como o RabbitMQ ou uma fila em mem√≥ria, como o Apache Pulsar.
- **Monitoramento e Alertas**: Monitore as falhas de envio e reenvios para enviar alertas ou notificar os administradores.

Agora que a persist√™ncia local foi implementada, temos uma solu√ß√£o robusta para garantir que mensagens n√£o sejam perdidas. Quer avan√ßar para outra √°rea, como melhorar o controle de falhas, ou algo mais? üòä




Implementar l√≥gica de **retry** e **fallback** para opera√ß√µes sens√≠veis, como o envio de mensagens ao Kafka, √© essencial para tornar o sistema resiliente a falhas tempor√°rias ou intermitentes. Vou detalhar como fazer isso e as melhores pr√°ticas:

---

### **1. O Que √© Retry?**
**Retry** √© a tentativa de repetir uma opera√ß√£o ap√≥s uma falha, com a esperan√ßa de que o problema seja tempor√°rio e a opera√ß√£o tenha sucesso em uma nova tentativa.

#### Exemplos de cen√°rios onde retry faz sentido:
- O Kafka est√° temporariamente indispon√≠vel (problemas de conectividade).
- Falhas transit√≥rias no envio (e.g., timeouts).

#### **Implementando Retry com KafkaTemplate**
O `KafkaTemplate` n√£o tem retry nativo, mas voc√™ pode implementar manualmente utilizando um bloco `try-catch` e um mecanismo de repeti√ß√£o controlada.

##### Exemplo b√°sico de retry:
```java
public void enviarComRetry(String topic, String key, Object value) {
    int maxRetries = 3; // N√∫mero m√°ximo de tentativas
    int attempt = 0;
    boolean enviado = false;

    while (attempt < maxRetries && !enviado) {
        try {
            kafkaTemplate.send(topic, key, value).get(); // Confirma envio
            log.info("Mensagem enviada com sucesso na tentativa {}", attempt + 1);
            enviado = true; // Sa√≠da do loop
        } catch (Exception e) {
            attempt++;
            log.error("Erro ao enviar mensagem para Kafka. Tentativa {}/{}", attempt, maxRetries, e);
            if (attempt == maxRetries) {
                throw new RuntimeException("Falha ao enviar mensagem para Kafka ap√≥s v√°rias tentativas", e);
            }
        }
    }
}
```

---

### **2. Backoff Estrat√©gico**
Repetir uma opera√ß√£o imediatamente pode sobrecarregar o sistema e n√£o resolver o problema. √â importante adicionar um atraso entre as tentativas, conhecido como **backoff**.

#### Tipos de Backoff:
1. **Fixo**: Um atraso constante entre tentativas.
2. **Exponencial**: Aumenta o atraso a cada falha (e.g., 100ms, 200ms, 400ms).
3. **Jitter**: Adiciona um valor aleat√≥rio ao backoff exponencial para evitar picos simult√¢neos.

##### Exemplo com backoff fixo:
```java
public void enviarComRetryBackoff(String topic, String key, Object value) {
    int maxRetries = 3;
    int attempt = 0;
    int backoffMillis = 1000; // 1 segundo

    while (attempt < maxRetries) {
        try {
            kafkaTemplate.send(topic, key, value).get();
            log.info("Mensagem enviada com sucesso na tentativa {}", attempt + 1);
            return; // Sucesso
        } catch (Exception e) {
            attempt++;
            log.error("Erro ao enviar mensagem. Tentativa {}/{}", attempt, maxRetries, e);
            if (attempt == maxRetries) {
                throw new RuntimeException("Falha ao enviar mensagem ap√≥s m√∫ltiplas tentativas", e);
            }
            try {
                Thread.sleep(backoffMillis); // Aguardar antes da pr√≥xima tentativa
            } catch (InterruptedException ie) {
                Thread.currentThread().interrupt();
                throw new RuntimeException("Retry interrompido", ie);
            }
        }
    }
}
```

---

### **3. O Que √© Fallback?**
**Fallback** √© a execu√ß√£o de uma a√ß√£o alternativa ou de compensa√ß√£o caso todas as tentativas falhem.

#### Exemplos de fallback:
- Persistir a mensagem em um banco de dados ou uma fila local para reprocessamento posterior.
- Enviar uma notifica√ß√£o ou alerta para o time respons√°vel.

##### Exemplo de fallback:
```java
public void enviarMensagemComFallback(String topic, String key, Object value) {
    int maxRetries = 3;
    try {
        enviarComRetry(topic, key, value); // Tentativa com retry
    } catch (Exception e) {
        log.error("Falha ao enviar mensagem ap√≥s retries. Executando fallback.", e);
        salvarParaReprocessamento(value); // Persistir para reprocessamento posterior
    }
}

private void salvarParaReprocessamento(Object value) {
    try {
        log.info("Salvando mensagem para reprocessamento: {}", value);
        // Exemplo: salvar em um banco de dados ou em uma fila local
        fallbackRepository.save(value);
    } catch (Exception e) {
        log.error("Falha ao salvar mensagem no fallback storage", e);
    }
}
```

---

### **4. Integra√ß√£o com Bibliotecas de Resili√™ncia**
Al√©m de implementar manualmente, voc√™ pode usar bibliotecas que abstraem essa l√≥gica de forma elegante, como o **Resilience4j**.

#### Exemplo com Resilience4j:
```java
RetryConfig config = RetryConfig.custom()
    .maxAttempts(3)
    .waitDuration(Duration.ofSeconds(1)) // Backoff fixo
    .build();

Retry retry = Retry.of("kafkaProducerRetry", config);

public void enviarMensagem(String topic, String key, Object value) {
    Retry.decorateCheckedRunnable(retry, () -> kafkaTemplate.send(topic, key, value).get()).run();
}
```

---

### **5. Cuidados ao Implementar Retry**
- **Evitar Efeitos Colaterais**: As opera√ß√µes devem ser idempotentes para evitar impactos duplicados (e.g., m√∫ltiplos registros no banco ou mensagens duplicadas).
- **Monitorar Erros**: Use logs ou m√©tricas para acompanhar falhas e retries.
- **Evitar Retry Infinito**: Sempre defina um n√∫mero m√°ximo de tentativas.

---

### Resumo
Implementar **retry** e **fallback** ajuda a garantir a resili√™ncia do sistema ao lidar com falhas. A estrat√©gia deve ser cuidadosamente configurada para evitar sobrecarga e impactos negativos. Se precisar, podemos explorar em mais detalhes ou integrar essas t√©cnicas em um exemplo mais completo!



Usar o **Spring Kafka** facilita bastante a implementa√ß√£o de l√≥gicas de retry e fallback, pois a biblioteca j√° oferece suporte nativo para v√°rias dessas funcionalidades, tanto no produtor quanto no consumidor. Abaixo, adapto os exemplos usando Spring Kafka.

---

## **1. Retry no Producer com Spring Kafka**

No caso do **Producer**, voc√™ pode usar as funcionalidades de retry oferecidas pelo Spring Retry, integrando-o ao envio de mensagens via `KafkaTemplate`.

### Configura√ß√£o do Retry com Backoff
Adicione uma configura√ß√£o de retry com backoff usando o `RetryTemplate` do Spring Retry.

```java
@Configuration
public class KafkaProducerConfig {

    @Bean
    public KafkaTemplate<String, Object> kafkaTemplate(ProducerFactory<String, Object> producerFactory) {
        return new KafkaTemplate<>(producerFactory, producerRetryTemplate());
    }

    private RetryTemplate producerRetryTemplate() {
        RetryTemplate retryTemplate = new RetryTemplate();

        // Configurar pol√≠tica de retry
        FixedBackOffPolicy backOffPolicy = new FixedBackOffPolicy();
        backOffPolicy.setBackOffPeriod(1000); // 1 segundo entre tentativas
        retryTemplate.setBackOffPolicy(backOffPolicy);

        // Configurar n√∫mero m√°ximo de tentativas
        SimpleRetryPolicy retryPolicy = new SimpleRetryPolicy();
        retryPolicy.setMaxAttempts(3); // 3 tentativas
        retryTemplate.setRetryPolicy(retryPolicy);

        return retryTemplate;
    }
}
```

### Enviando Mensagens com Retry
Use o `KafkaTemplate` normalmente; o retry ser√° gerenciado automaticamente.

```java
@Service
public class PixProducer {

    private final KafkaTemplate<String, Object> kafkaTemplate;

    public PixProducer(KafkaTemplate<String, Object> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public void enviarMensagem(String topic, String key, Object value) {
        kafkaTemplate.send(topic, key, value).addCallback(
            success -> log.info("Mensagem enviada com sucesso: {}", success.getProducerRecord()),
            failure -> log.error("Erro ao enviar mensagem para o Kafka", failure)
        );
    }
}
```

---

## **2. Retry no Consumer com Spring Kafka**

O Spring Kafka suporta retry nativo no consumidor com o uso de `SeekToCurrentErrorHandler` ou outros `ErrorHandler`.

### Configura√ß√£o do Retry no Consumer
Crie um `ConcurrentKafkaListenerContainerFactory` e configure o retry com backoff.

```java
@Configuration
public class KafkaConsumerConfig {

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
            ConsumerFactory<String, Object> consumerFactory) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory =
                new ConcurrentKafkaListenerContainerFactory<>();

        factory.setConsumerFactory(consumerFactory);

        // Configura√ß√£o de retry com backoff
        factory.setErrorHandler(
                new SeekToCurrentErrorHandler(new DeadLetterPublishingRecoverer(kafkaTemplate()), 
                                              new FixedBackOff(1000, 3)) // 1s, 3 tentativas
        );

        return factory;
    }

    @Bean
    public KafkaTemplate<String, Object> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }

    @Bean
    public ProducerFactory<String, Object> producerFactory() {
        return new DefaultKafkaProducerFactory<>(producerConfigs());
    }

    @Bean
    public Map<String, Object> producerConfigs() {
        Map<String, Object> props = new HashMap<>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        return props;
    }
}
```

---

## **3. Fallback para DLQ no Consumer**

A configura√ß√£o acima inclui um **DeadLetterPublishingRecoverer** para redirecionar mensagens falhas a uma Dead Letter Queue (DLQ).

### Criando um Listener para DLQ
O DLQ √© configurado automaticamente pelo Spring Kafka. Voc√™ pode criar um listener para monitorar mensagens enviadas para a fila de erro.

```java
@Component
public class DlqListener {

    @KafkaListener(topics = "pix-topic-dlq")
    public void processarMensagemDLQ(ConsumerRecord<String, Object> record) {
        log.error("Mensagem enviada para DLQ: {}", record);
        // Processar ou notificar time respons√°vel
    }
}
```

---

## **4. Garantia de Idempot√™ncia no Consumer**

Para garantir idempot√™ncia no consumidor, voc√™ pode usar um identificador √∫nico (`key`) da mensagem e armazenar um registro de processamentos j√° realizados, evitando duplica√ß√£o.

### Exemplo com Cache
```java
@Service
public class PixConsumer {

    private final Set<String> processedKeys = ConcurrentHashMap.newKeySet();

    @KafkaListener(topics = "pix-topic", groupId = "pix-group")
    public void consumirMensagem(ConsumerRecord<String, PixDTO> record) {
        String key = record.key();
        if (processedKeys.contains(key)) {
            log.info("Mensagem j√° processada: {}", key);
            return; // Ignorar mensagem duplicada
        }

        try {
            log.info("Processando mensagem: {}", record);
            processedKeys.add(key);
            // Processar l√≥gica do Pix
        } catch (Exception e) {
            log.error("Erro ao processar mensagem", e);
            throw e; // Deixar o retry/dlq tratar a falha
        }
    }
}
```

---

## Resumo

Essas implementa√ß√µes s√£o pr√°ticas e alinhadas ao ecossistema do Spring Kafka. O uso de `RetryTemplate`, `SeekToCurrentErrorHandler`, e `DeadLetterPublishingRecoverer` fornece mecanismos robustos para retry e fallback. Sempre monitore suas m√©tricas e ajuste os par√¢metros de retry e DLQ de acordo com as necessidades do sistema.

Se precisar de algum ajuste ou de mais explica√ß√µes, √© s√≥ pedir!









A estrutura de pacotes para aplica√ß√µes que utilizam **Scheduler** no Spring Boot deve ser organizada para refletir os princ√≠pios de modularidade e responsabilidade √∫nica. Uma boa pr√°tica √© separar a l√≥gica de agendamento da l√≥gica de neg√≥cios e manter a configura√ß√£o desacoplada. Aqui est√° uma sugest√£o de estrutura de pacotes que voc√™ pode usar:

---

### **1. Estrutura Sugerida**

```plaintext
br.com.raysonsatos.producer_a
‚îú‚îÄ‚îÄ config               # Configura√ß√µes e Beans da aplica√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ KafkaProducerConfig.java
‚îÇ
‚îú‚îÄ‚îÄ domain               # Entidades ou objetos de dom√≠nio (opcional, depende da aplica√ß√£o)
‚îÇ   ‚îî‚îÄ‚îÄ Pix.java
‚îÇ
‚îú‚îÄ‚îÄ dto                  # Objetos de transfer√™ncia de dados (Data Transfer Objects)
‚îÇ   ‚îî‚îÄ‚îÄ PixDTO.java
‚îÇ
‚îú‚îÄ‚îÄ service              # Servi√ßos de neg√≥cio (l√≥gica principal)
‚îÇ   ‚îî‚îÄ‚îÄ ProducerService.java
‚îÇ
‚îú‚îÄ‚îÄ scheduler            # Componentes respons√°veis por tarefas agendadas
‚îÇ   ‚îî‚îÄ‚îÄ MessageScheduler.java
‚îÇ
‚îú‚îÄ‚îÄ repository           # Interfaces para persist√™ncia de dados
‚îÇ   ‚îî‚îÄ‚îÄ PixRepository.java
‚îÇ
‚îú‚îÄ‚îÄ controller           # Controladores REST (API) se necess√°rio
‚îÇ   ‚îî‚îÄ‚îÄ PixController.java
‚îÇ
‚îú‚îÄ‚îÄ util                 # Classes utilit√°rias e helpers (opcional)
‚îÇ   ‚îî‚îÄ‚îÄ KafkaUtils.java
‚îÇ
‚îî‚îÄ‚îÄ ProducerAApplication.java  # Classe principal da aplica√ß√£o
```

---

### **2. Justificativa da Estrutura**

1. **`config`**:
   - Para todas as configura√ß√µes da aplica√ß√£o, como `KafkaProducerConfig`, configura√ß√µes do Scheduler, e outros Beans.
   - Mant√©m as configura√ß√µes centralizadas e facilita a manuten√ß√£o.

2. **`domain`**:
   - Armazena as entidades da aplica√ß√£o, como classes representando objetos de dom√≠nio (e.g., `Pix.java`).
   - Separar o dom√≠nio ajuda a seguir o conceito de Domain-Driven Design.

3. **`dto`**:
   - Armazena classes utilizadas para transferir dados entre camadas, como o `PixDTO`.
   - Garante que o modelo de dom√≠nio n√£o seja exposto diretamente.

4. **`service`**:
   - Cont√©m a l√≥gica de neg√≥cios, como a gera√ß√£o de mensagens para o Kafka.
   - Facilita o teste e reutiliza√ß√£o da l√≥gica central.

5. **`scheduler`**:
   - Cont√©m todas as classes relacionadas ao agendamento de tarefas.
   - Separar agendadores permite que altera√ß√µes na periodicidade ou l√≥gica de agendamento n√£o impactem outras partes da aplica√ß√£o.

6. **`repository`**:
   - Para persist√™ncia de dados, normalmente com Spring Data JPA ou outro framework de ORM.
   - Centraliza o acesso a dados.

7. **`controller`**:
   - Para expor endpoints REST, se necess√°rio, facilitando a comunica√ß√£o com outros sistemas ou usu√°rios.

8. **`util`**:
   - Para classes que encapsulam funcionalidades gen√©ricas, como m√©todos auxiliares para formata√ß√£o ou valida√ß√£o.

---

### **3. Exemplo Espec√≠fico: Aplica√ß√£o com Scheduler**

Se a aplica√ß√£o for simples e n√£o envolver persist√™ncia ou uma API REST, voc√™ pode omitir os pacotes `domain`, `repository`, e `controller`. A estrutura ficaria assim:

```plaintext
br.com.raysonsatos.producer_a
‚îú‚îÄ‚îÄ config               # Configura√ß√µes do Kafka e Scheduler
‚îÇ   ‚îî‚îÄ‚îÄ KafkaProducerConfig.java
‚îÇ
‚îú‚îÄ‚îÄ service              # L√≥gica de envio de mensagens
‚îÇ   ‚îî‚îÄ‚îÄ ProducerService.java
‚îÇ
‚îú‚îÄ‚îÄ scheduler            # Tarefas agendadas
‚îÇ   ‚îî‚îÄ‚îÄ MessageScheduler.java
‚îÇ
‚îî‚îÄ‚îÄ ProducerAApplication.java  # Classe principal
```

---

Essa estrutura √© flex√≠vel e pode ser adaptada conforme as necessidades do projeto. Separar as responsabilidades facilita a escalabilidade, testes e manuten√ß√£o do c√≥digo.









Para configurar seu projeto Spring Boot com **Spring Cloud AWS** e **AWS Secrets Manager** para utilizar perfis diferentes (local, dev, hml e prod) com base na m√°quina de execu√ß√£o (local ou AWS), voc√™ pode seguir as etapas abaixo.

A ideia √© usar o `application.yml` ou `application.properties` para configurar diferentes perfis e carregar os segredos do **AWS Secrets Manager** dependendo do ambiente. Vamos configurar isso da seguinte forma:

### **1. Estrutura do `application.yml` para Perfis Diferentes**

Aqui est√° um exemplo de como organizar as configura√ß√µes no `application.yml`, dividindo os perfis `local`, `dev`, `hml` e `prod`.

```yaml
# application.yml

spring:
  cloud:
    aws:
      region:
        static: us-east-1  # Defina a regi√£o AWS padr√£o
      secrets-manager:
        enabled: true  # Habilitar o uso do Secrets Manager

---
# Perfil Local
spring:
  profiles: local
  cloud:
    aws:
      secrets-manager:
        name: your-secrets-manager-local  # Nome do segredo para o perfil local
        fail-fast: false  # N√£o falhar se n√£o encontrar o segredo (√∫til para desenvolvimento local)
  kafka:
    bootstrap-servers: localhost:9092  # Configura√ß√£o para o Kafka local
    properties:
      security.protocol: PLAINTEXT
    consumer:
      group-id: local-group

---
# Perfil Dev
spring:
  profiles: dev
  cloud:
    aws:
      secrets-manager:
        name: your-secrets-manager-dev  # Nome do segredo para o perfil de dev
        fail-fast: true  # Falha caso n√£o consiga recuperar o segredo
  kafka:
    bootstrap-servers: your-kafka-dev-broker-url:9092  # URL do Kafka na AWS (ex: MSK)
    properties:
      security.protocol: SASL_SSL
      sasl.mechanism: PLAIN
      sasl.jaas.config: >
        org.apache.kafka.common.security.plain.PlainLoginModule required
        username="${kafka.username}"
        password="${kafka.password}";

---
# Perfil HML
spring:
  profiles: hml
  cloud:
    aws:
      secrets-manager:
        name: your-secrets-manager-hml  # Nome do segredo para o perfil de homologa√ß√£o
        fail-fast: true
  kafka:
    bootstrap-servers: your-kafka-hml-broker-url:9092  # URL do Kafka para homologa√ß√£o
    properties:
      security.protocol: SASL_SSL
      sasl.mechanism: PLAIN
      sasl.jaas.config: >
        org.apache.kafka.common.security.plain.PlainLoginModule required
        username="${kafka.username}"
        password="${kafka.password}";

---
# Perfil Prod
spring:
  profiles: prod
  cloud:
    aws:
      secrets-manager:
        name: your-secrets-manager-prod  # Nome do segredo para o perfil de produ√ß√£o
        fail-fast: true
  kafka:
    bootstrap-servers: your-kafka-prod-broker-url:9092  # URL do Kafka em produ√ß√£o
    properties:
      security.protocol: SASL_SSL
      sasl.mechanism: PLAIN
      sasl.jaas.config: >
        org.apache.kafka.common.security.plain.PlainLoginModule required
        username="${kafka.username}"
        password="${kafka.password}";
```

### **2. Configura√ß√£o de Perfis no AWS Secrets Manager**

Cada perfil (local, dev, hml, prod) deve ter um segredo no **AWS Secrets Manager** com informa√ß√µes espec√≠ficas de cada ambiente. O nome do segredo ser√° passado no par√¢metro `name`, conforme configurado no `application.yml`.

Exemplo de formato do segredo para cada ambiente:

- **Local:**
```json
{
  "kafka.username": "local_user",
  "kafka.password": "local_password"
}
```

- **Dev:**
```json
{
  "kafka.username": "dev_user",
  "kafka.password": "dev_password"
}
```

- **HML:**
```json
{
  "kafka.username": "hml_user",
  "kafka.password": "hml_password"
}
```

- **Prod:**
```json
{
  "kafka.username": "prod_user",
  "kafka.password": "prod_password"
}
```

### **3. Como Passar o Perfil para a Aplica√ß√£o**

Voc√™ pode passar o perfil ativo para o Spring Boot ao iniciar a aplica√ß√£o, de duas formas:

1. **Via linha de comando** ao iniciar a aplica√ß√£o:

```bash
java -jar your-app.jar --spring.profiles.active=dev
```

Ou para o perfil de produ√ß√£o:

```bash
java -jar your-app.jar --spring.profiles.active=prod
```

2. **Via vari√°vel de ambiente**:

No seu ambiente AWS (como EC2 ou ECS), voc√™ pode definir a vari√°vel de ambiente `SPRING_PROFILES_ACTIVE` com o valor desejado:

```bash
export SPRING_PROFILES_ACTIVE=dev
```

### **4. Configura√ß√£o para Local (Desenvolvimento)**
Para o perfil `local`, voc√™ pode definir configura√ß√µes alternativas, como o Kafka local ou o uso de um banco de dados em mem√≥ria. Por exemplo:

```yaml
# application-local.yml
spring:
  kafka:
    bootstrap-servers: localhost:9092  # Kafka rodando localmente
```

### **5. Configura√ß√£o no AWS**

Quando a aplica√ß√£o estiver rodando na AWS, o Spring Cloud AWS automaticamente ir√° buscar os segredos no **AWS Secrets Manager** de acordo com o nome definido em cada perfil (`your-secrets-manager-dev`, `your-secrets-manager-prod`, etc.). Assim, as credenciais do Kafka e outras informa√ß√µes sens√≠veis ser√£o recuperadas de forma autom√°tica.

Certifique-se de que a inst√¢ncia EC2 ou o container ECS tenha permiss√µes adequadas via **IAM role** para acessar o **AWS Secrets Manager**.

### **6. Testando Localmente**

Ao testar localmente, voc√™ pode usar o perfil `local` e criar um arquivo `application-local.yml` contendo configura√ß√µes espec√≠ficas, como um Kafka local e configura√ß√µes para desenvolvimento. Isso permite que sua aplica√ß√£o tenha uma configura√ß√£o diferente para ambientes locais e para os ambientes AWS (dev, hml, prod).

### **Conclus√£o**

Com a configura√ß√£o acima, voc√™ ter√° perfis separados para `local`, `dev`, `hml` e `prod`, permitindo um controle refinado das configura√ß√µes em cada ambiente. O Spring Cloud AWS cuida da recupera√ß√£o dos segredos automaticamente, sem a necessidade de manipula√ß√£o expl√≠cita de credenciais no c√≥digo ou no `application.yml`. Isso melhora a seguran√ßa e facilita a adapta√ß√£o para diferentes ambientes de execu√ß√£o.






Para que os segredos armazenados no **AWS Secrets Manager** sejam automaticamente convertidos em vari√°veis de ambiente na sua aplica√ß√£o, voc√™ pode usar um processo autom√°tico durante a inicializa√ß√£o da sua aplica√ß√£o, onde voc√™ recupera os segredos do AWS Secrets Manager e os define como vari√°veis de ambiente. Isso pode ser feito de maneira pr√°tica com a utiliza√ß√£o de um **AWS Lambda** ou **um script customizado** que configura as vari√°veis de ambiente ao iniciar a aplica√ß√£o.

### **Passos para Transformar Segredos em Vari√°veis de Ambiente Automaticamente**

#### **1. Recuperando Segredos no AWS Secrets Manager**
Voc√™ j√° configurou o seu segredo no **AWS Secrets Manager**. O segredo ser√° um objeto JSON com os campos de credenciais, como `username` e `password`.

Exemplo do segredo:
```json
{
  "username": "your_username",
  "password": "your_password"
}
```

#### **2. Carregando Segredos e Configurando Vari√°veis de Ambiente**

Para fazer isso de maneira autom√°tica, voc√™ pode usar um **script de inicializa√ß√£o** no **Docker** ou em um script de inicializa√ß√£o no ambiente de execu√ß√£o (por exemplo, no EC2 ou ECS).

Aqui est√° um exemplo de como fazer isso em uma aplica√ß√£o Spring Boot. O c√≥digo abaixo recupera os segredos e define como vari√°veis de ambiente.

##### **Exemplo em Java com Spring Boot**

1. **Depend√™ncias**

Adicione as depend√™ncias necess√°rias para o SDK da AWS no seu `pom.xml`:

```xml
<dependencies>
    <dependency>
        <groupId>software.amazon.awssdk</groupId>
        <artifactId>secretsmanager</artifactId>
        <version>2.x.x</version>
    </dependency>
</dependencies>
```

2. **Script para Carregar Segredos e Definir Vari√°veis de Ambiente**

Aqui est√° o c√≥digo Java que recupera os segredos do AWS Secrets Manager e define as vari√°veis de ambiente:

```java
import software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider;
import software.amazon.awssdk.regions.Region;
import software.amazon.awssdk.services.secretsmanager.SecretsManagerClient;
import software.amazon.awssdk.services.secretsmanager.model.GetSecretValueRequest;
import software.amazon.awssdk.services.secretsmanager.model.GetSecretValueResponse;

import java.util.Map;
import com.fasterxml.jackson.databind.ObjectMapper;

public class SecretsLoader {

    public static void main(String[] args) {
        // Configurar o cliente do Secrets Manager
        SecretsManagerClient client = SecretsManagerClient.builder()
                .region(Region.US_EAST_1) // Substitua pela sua regi√£o
                .credentialsProvider(DefaultCredentialsProvider.create())
                .build();

        // Recuperar o segredo
        GetSecretValueRequest request = GetSecretValueRequest.builder()
                .secretId("kafka-sasl-credentials") // Nome do segredo
                .build();

        GetSecretValueResponse response = client.getSecretValue(request);
        ObjectMapper mapper = new ObjectMapper();

        try {
            // Parse o JSON do segredo
            Map<String, String> credentials = mapper.readValue(response.secretString(), Map.class);
            // Definir como vari√°veis de ambiente
            System.setProperty("KAFKA_USERNAME", credentials.get("username"));
            System.setProperty("KAFKA_PASSWORD", credentials.get("password"));

            // Imprimir para verificar se as vari√°veis foram configuradas corretamente
            System.out.println("KAFKA_USERNAME: " + System.getProperty("KAFKA_USERNAME"));
            System.out.println("KAFKA_PASSWORD: " + System.getProperty("KAFKA_PASSWORD"));
        } catch (Exception e) {
            throw new RuntimeException("Erro ao carregar segredos do Secrets Manager", e);
        }
    }
}
```

3. **Configurando no `application.yml`**

No seu `application.yml`, voc√™ pode referenciar essas vari√°veis de ambiente como segue:

```yaml
spring:
  kafka:
    bootstrap-servers: your-broker-url:9092
    properties:
      security.protocol: SASL_SSL
      sasl.mechanism: PLAIN
      sasl.jaas.config: >
        org.apache.kafka.common.security.plain.PlainLoginModule required
        username="${KAFKA_USERNAME}"
        password="${KAFKA_PASSWORD}";
```

#### **3. Alternativa com Script de Inicializa√ß√£o no Docker**

Se voc√™ estiver usando **Docker**, pode incluir um script de inicializa√ß√£o que execute esse c√≥digo Java para configurar as vari√°veis de ambiente antes de rodar sua aplica√ß√£o Spring Boot.

Aqui est√° um exemplo de como configurar isso em um Dockerfile:

1. **Dockerfile**

```dockerfile
FROM openjdk:11-jre-slim

WORKDIR /app

# Copie os arquivos do projeto
COPY target/your-application.jar /app/

# Instale o AWS CLI para acessar o Secrets Manager
RUN apt-get update && apt-get install -y awscli

# Script de inicializa√ß√£o
COPY init-secrets.sh /app/

# Execute o script de inicializa√ß√£o e, em seguida, a aplica√ß√£o
CMD ["sh", "init-secrets.sh"]
```

2. **init-secrets.sh**

```bash
#!/bin/bash

# Recupera as credenciais do AWS Secrets Manager
KAFKA_CREDS=$(aws secretsmanager get-secret-value --secret-id kafka-sasl-credentials --query SecretString --output text)

# Extrai os valores de username e password
KAFKA_USERNAME=$(echo $KAFKA_CREDS | jq -r '.username')
KAFKA_PASSWORD=$(echo $KAFKA_CREDS | jq -r '.password')

# Exporta como vari√°veis de ambiente
export KAFKA_USERNAME
export KAFKA_PASSWORD

# Executa a aplica√ß√£o Spring Boot
java -jar /app/your-application.jar
```

O script usa o **AWS CLI** para acessar os segredos e o **jq** para parsear o JSON. Ele define as vari√°veis de ambiente antes de iniciar a aplica√ß√£o Spring Boot.

#### **4. Configura√ß√£o no ECS ou EC2**

Se voc√™ estiver usando o **Amazon ECS** ou **EC2**, pode configurar um script de inicializa√ß√£o similar ao exemplo acima, ou usar o **AWS Systems Manager Parameter Store** ou **Secrets Manager** diretamente para passar as vari√°veis de ambiente para o cont√™iner ou inst√¢ncia.

---

### **Conclus√£o**

A forma de configurar as vari√°veis de ambiente automaticamente a partir dos segredos do AWS Secrets Manager depende do seu ambiente de execu√ß√£o:

- **Para aplica√ß√µes locais ou em cont√™ineres (Docker),** voc√™ pode usar o c√≥digo Java para recuperar os segredos e definir as vari√°veis de ambiente diretamente.
- **Para ambientes como ECS ou EC2,** voc√™ pode utilizar o AWS CLI ou o SDK para configurar as vari√°veis antes de iniciar a aplica√ß√£o.

Essa abordagem garante que voc√™ possa manter as credenciais seguras e fora do c√≥digo, seguindo o princ√≠pio do **12-factor app**.








# Aqui

Se voc√™ deseja usar **AWS Secrets Manager** para armazenar de forma segura o **usu√°rio** e a **senha** para autentica√ß√£o no Kafka com SASL/PLAIN, aqui est√° o processo:

---

### **1. Configurando o Segredo no AWS Secrets Manager**

No AWS Secrets Manager, crie um segredo para armazenar as credenciais. Por exemplo:

- **Secret Name:** `kafka-sasl-credentials`
- **Secret Value (JSON):**
  ```json
  {
    "username": "your_username",
    "password": "your_password"
  }
  ```

---

### **2. Adicionando Depend√™ncias**

No seu `pom.xml`, inclua a depend√™ncia para integrar com o **AWS SDK** para Java:

```xml
<dependencies>
    <dependency>
        <groupId>software.amazon.awssdk</groupId>
        <artifactId>secretsmanager</artifactId>
        <version>2.20.35</version> <!-- Use a vers√£o mais recente dispon√≠vel -->
    </dependency>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>
</dependencies>
```

---

### **3. Recuperando o Segredo no C√≥digo**

Crie um componente para buscar as credenciais do Secrets Manager:

```java
import org.springframework.stereotype.Component;
import software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider;
import software.amazon.awssdk.regions.Region;
import software.amazon.awssdk.services.secretsmanager.SecretsManagerClient;
import software.amazon.awssdk.services.secretsmanager.model.GetSecretValueRequest;
import software.amazon.awssdk.services.secretsmanager.model.GetSecretValueResponse;

import com.fasterxml.jackson.databind.ObjectMapper;

import java.util.Map;

@Component
public class SecretsManagerUtil {

    private final SecretsManagerClient secretsManagerClient;

    public SecretsManagerUtil() {
        this.secretsManagerClient = SecretsManagerClient.builder()
                .region(Region.US_EAST_1) // Substitua pela sua regi√£o
                .credentialsProvider(DefaultCredentialsProvider.create())
                .build();
    }

    public Map<String, String> getKafkaCredentials(String secretName) {
        GetSecretValueRequest request = GetSecretValueRequest.builder()
                .secretId(secretName)
                .build();

        GetSecretValueResponse response = secretsManagerClient.getSecretValue(request);

        try {
            ObjectMapper mapper = new ObjectMapper();
            return mapper.readValue(response.secretString(), Map.class);
        } catch (Exception e) {
            throw new RuntimeException("Erro ao obter segredo do Secrets Manager", e);
        }
    }
}
```

---

### **4. Configurando SASL/PLAIN Dinamicamente**

Use as credenciais recuperadas para configurar o Kafka dinamicamente:

```java
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.apache.kafka.clients.CommonClientConfigs;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.config.SaslConfigs;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaProducerConfig {

    private final SecretsManagerUtil secretsManagerUtil;

    public KafkaProducerConfig(SecretsManagerUtil secretsManagerUtil) {
        this.secretsManagerUtil = secretsManagerUtil;
    }

    @Bean
    public Map<String, Object> producerConfigs() {
        Map<String, Object> props = new HashMap<>();

        // Recupera as credenciais do AWS Secrets Manager
        Map<String, String> credentials = secretsManagerUtil.getKafkaCredentials("kafka-sasl-credentials");

        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "your-broker-url:9092");
        props.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
        props.put(SaslConfigs.SASL_MECHANISM, "PLAIN");
        props.put(SaslConfigs.SASL_JAAS_CONFIG, String.format(
                "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"%s\" password=\"%s\";",
                credentials.get("username"), credentials.get("password")
        ));
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);

        return props;
    }
}
```

---

### **5. Configurando `application.yml`**
Configure apenas as propriedades b√°sicas no `application.yml`:

```yaml
spring:
  kafka:
    producer:
      properties:
        bootstrap.servers: your-broker-url:9092
```

---

### **6. Seguran√ßa em Produ√ß√£o**

- **Permiss√µes IAM:** Certifique-se de que a aplica√ß√£o tem permiss√µes espec√≠ficas para acessar o Secrets Manager.
  - Exemplo de pol√≠tica IAM:
    ```json
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Action": "secretsmanager:GetSecretValue",
          "Resource": "arn:aws:secretsmanager:your-region:your-account-id:secret:kafka-sasl-credentials"
        }
      ]
    }
    ```

- **Rota√ß√£o de Segredos:** O AWS Secrets Manager permite a rota√ß√£o autom√°tica de segredos, garantindo que as credenciais sejam atualizadas regularmente sem interven√ß√£o manual.

---

### Benef√≠cios
- Segrega√ß√£o de credenciais sens√≠veis do c√≥digo-fonte.
- Compatibilidade com o **12-factor app**, externalizando configura√ß√µes.
- F√°cil integra√ß√£o com outros servi√ßos AWS.

Essa abordagem fornece uma solu√ß√£o segura e escal√°vel para gerenciar credenciais Kafka em produ√ß√£o.